{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeanettemumford/.pyenv/versions/3.8.5/lib/python3.8/site-packages/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/jeanettemumford/Dropbox/Research/Projects/RT_sims/Code')\n",
    "from functions import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.stats import exponnorm, gamma\n",
    "\n",
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at range of durations and estimate from impulse and 1s duration regressors.\n",
    "\n",
    "dur_vec = np.arange(0, 5, .05)\n",
    "n_sim = len(dur_vec)\n",
    "beta_impulse = []\n",
    "res_impulse = []\n",
    "beta_1s = []\n",
    "res_1s = []\n",
    "\n",
    "frame_times = np.arange(50)\n",
    "scan_length = len(frame_times)\n",
    "onsets = [20]\n",
    "amp = 1\n",
    "reg_impulse, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, .1, amp), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "reg_1s, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, 1, amp), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "\n",
    "for sim in range(0, n_sim):\n",
    "    dat_loop, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, dur_vec[sim], amp), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "    contrasts = np.array([[0, 1]])\n",
    "    x_impulse = np.concatenate((np.ones(reg_impulse.shape),\n",
    "                    reg_impulse), axis=1)\n",
    "    beta_impulse_loop, _, _, pred_impulse, _  = runreg(dat_loop, x_impulse, contrasts, \n",
    "            hp_filter=True, compute_stats=True)\n",
    "    x_1s = np.concatenate((np.ones(reg_impulse.shape),\n",
    "                    reg_1s), axis=1)\n",
    "    beta_1s_loop, _, _, pred_1s, _  = runreg(dat_loop, x_1s, contrasts, \n",
    "            hp_filter=True, compute_stats=True)\n",
    "    beta_impulse.append(beta_impulse_loop)\n",
    "    res_impulse.append(sum((pred_impulse - dat_loop)**2))\n",
    "    beta_1s.append(beta_1s_loop)\n",
    "    res_1s.append(sum((pred_1s - dat_loop)**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(np.array(beta_impulse)/10, dur_vec, 'o')\n",
    "plt.xlabel('beta impulse regressor / 10')\n",
    "plt.ylabel('Stimulus duration')\n",
    "abline(1, 0)\n",
    "plt.show()\n",
    "plt.plot(beta_1s, dur_vec, 'o')\n",
    "plt.xlabel('beta 1s duration regressor')\n",
    "plt.ylabel('Stimulus duration')\n",
    "abline(1, 0)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(dur_vec, res_impulse, label='impulse')\n",
    "plt.plot(dur_vec, res_1s, label='1s')\n",
    "plt.xlabel('Stimulus duration')\n",
    "plt.ylabel('Sum of squared residuals')\n",
    "plt.legend(loc = 'upper left', prop={'size': 8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the 1s duration regressor is less susceptible to misfitting the data, in the range we'd expect RTs to be.  Also, the interpretation of the parameter estimate seems to match up well with the duration.  This is helpful, but I need to further understand the behavior for a range of trials with a range of RTs within a single run.  Here I only looked at a single trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_times = np.arange(50)\n",
    "scan_length = len(frame_times)\n",
    "onsets = [20]\n",
    "duration_rt1 = [2]\n",
    "amplitude_1 = [1]\n",
    "\n",
    "duration_rt2 = 1\n",
    "amplitude_2 = [2]\n",
    "\n",
    "\n",
    "dur_2_amp_1, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, duration_rt1, amplitude_1), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "dur_1_amp_2, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, duration_rt2, amplitude_2), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "plt.plot(dur_2_amp_1, label = 'Duration =2s, Amplitude = 1')\n",
    "plt.plot(dur_1_amp_2, label = 'Duration =1s, Amplitude = 2')\n",
    "plt.legend(loc = 'upper left', prop={'size': 8})\n",
    "plt.show()\n",
    "\n",
    "\n",
    "frame_times = np.arange(50)\n",
    "scan_length = len(frame_times)\n",
    "onsets = [20]\n",
    "duration_rt1 = [1]\n",
    "amplitude_1 = [1]\n",
    "\n",
    "duration_rt2 = 1.5\n",
    "amplitude_2 = [1]\n",
    "\n",
    "\n",
    "reg1, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, duration_rt1, amplitude_1), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "reg2, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, duration_rt2, amplitude_2), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "plt.plot(reg1, label = 'RT duration')\n",
    "plt.plot(reg2, label = 'Stimulus duration')\n",
    "plt.legend(loc = 'upper left', prop={'size': 8})\n",
    "plt.show()\n",
    "\n",
    "np.corrcoef(reg1.T, reg2.T)\n",
    "\n",
    "\n",
    "frame_times = np.arange(50)\n",
    "scan_length = len(frame_times)\n",
    "onsets = [20]\n",
    "duration_rt1 = [1]\n",
    "amplitude_1 = [1]\n",
    "\n",
    "onsets2 = 21\n",
    "duration_rt2 = .5\n",
    "amplitude_2 = [1]\n",
    "\n",
    "\n",
    "reg1, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets, duration_rt1, amplitude_1), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "reg2, _ = hemodynamic_models.compute_regressor(\n",
    "                      make_3column_onsets(onsets2, duration_rt2, amplitude_2), \n",
    "                      'spm', frame_times, oversampling=16)\n",
    "plt.plot(reg1, label = 'RT duration')\n",
    "plt.plot(reg2, label = 'Tail end of stimulus duration')\n",
    "plt.legend(loc = 'upper left', prop={'size': 8})\n",
    "plt.show()\n",
    "\n",
    "np.corrcoef(reg1.T, reg2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_times = np.arange(100)\n",
    "scan_length = len(frame_times)\n",
    "onsets = np.arange(10, 50, 3)\n",
    "#onsets = 10\n",
    "print(onsets)\n",
    "duration_rt = [2]*len(onsets)\n",
    "#duration_rt = 30\n",
    "print(duration_rt)\n",
    "amplitude_1 = [1]*len(onsets)\n",
    "\n",
    "des_3col = make_3column_onsets(onsets, duration_rt, amplitude_1)\n",
    "\n",
    "reg_unconv, _ = hemodynamic_models.compute_regressor(\n",
    "                      des_3col, None, frame_times, \n",
    "                      oversampling=16)\n",
    "reg, _ = hemodynamic_models.compute_regressor(\n",
    "                      des_3col, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "\n",
    "plt.plot(reg)\n",
    "plt.plot(reg_unconv)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teasing apart possible parameter interpretation\n",
    "frame_times = np.arange(500)\n",
    "scan_length = len(frame_times)\n",
    "onsets = np.arange(10, 480, 10)\n",
    "\n",
    "duration_rt = gamma.rvs(a = 1.7, loc = .5, scale = .49, size = onsets.shape)\n",
    "amplitude_1 = np.ones(onsets.shape)\n",
    "mn_rt = np.mean(duration_rt)\n",
    "#duration_cons = [mn_rt, mn_rt, mn_rt]\n",
    "duration_cons = np.ones(onsets.shape)\n",
    "amplitude_rt_centered = duration_rt - np.mean(duration_rt)\n",
    "mn_rt_dur = np.ones(onsets.shape)*mn_rt\n",
    "\n",
    "rt_dur_reg_info = make_3column_onsets(onsets, duration_rt, amplitude_1)\n",
    "unmod_reg_info = make_3column_onsets(onsets, duration_cons, amplitude_1)\n",
    "mod_rt_centered_reg_info = make_3column_onsets(onsets, duration_cons, amplitude_rt_centered)\n",
    "\n",
    "mn_rt_dur_reg_info = make_3column_onsets(onsets, mn_rt_dur, amplitude_1)\n",
    "\n",
    "rt_dur, _ = hemodynamic_models.compute_regressor(\n",
    "                      rt_dur_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "mn_rt_dur, _ = hemodynamic_models.compute_regressor(\n",
    "                      mn_rt_dur_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "unmod_reg, _ = hemodynamic_models.compute_regressor(\n",
    "                      unmod_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "mod_rt, _ = hemodynamic_models.compute_regressor(\n",
    "                      mod_rt_centered_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "# orthogonalize by first fitting unmod to rt_dur\n",
    "x_unmod_only = sm.add_constant(unmod_reg)\n",
    "#contrasts = np.array([[0, 1]])\n",
    "#_, _, _, predy, _ = runreg(rt_dur, x_unmod_only, contrasts, hp_filter=False, \n",
    "#                           compute_stats=False)\n",
    "contrasts = np.array([[1]])\n",
    "_, _, _, predy, _ = runreg(rt_dur, unmod_reg, contrasts, hp_filter=False, \n",
    "                           compute_stats=False)\n",
    "#rt_dur_orth = rt_dur - predy\n",
    "rt_dur_orth_reg_info = make_3column_onsets(np.array(onsets)+1, \n",
    "                                           np.array(duration_rt)-1, amplitude_1)\n",
    "rt_dur_orth, _ = hemodynamic_models.compute_regressor(\n",
    "                      rt_dur_orth_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)  \n",
    "\n",
    "\n",
    "bold = 100 + rt_dur*5 + np.random.normal(0, 0, (scan_length, 1))\n",
    "contrasts = np.array([[1, 0], [0, 1]])\n",
    "x_rt_dur = sm.add_constant(rt_dur)\n",
    "con_dur_rt, t_dur_rt, p_dur_rt, mod_fit_dur_rt, _ = runreg(bold, x_rt_dur, \n",
    "                                contrasts, hp_filter=False, compute_stats=True)\n",
    "print('RT dur model')\n",
    "print(con_dur_rt)\n",
    "#print(p_dur_rt)\n",
    "\n",
    "contrasts = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "x_cons_rt = np.concatenate((np.ones(unmod_reg.shape), unmod_reg, rt_dur_orth), axis=1)\n",
    "con_cons_rt, t_cons_rt, p_cons_rt, mod_fit_cons_rt, _ = runreg(bold, x_cons_rt, contrasts, hp_filter=False, compute_stats=True)\n",
    "print('Unmodulated and Orthogonalized RT dur')\n",
    "print(con_cons_rt)\n",
    "#print(p_cons_rt)\n",
    "\n",
    "x_cons_rt_mod = np.concatenate((np.ones(unmod_reg.shape), unmod_reg, mod_rt), axis=1)\n",
    "con_cons_rt_mod, t_cons_rt_mod, p_cons_rt_mod, mod_fit_cons_rt_mod, _ = runreg(bold, x_cons_rt_mod, contrasts, hp_filter=False, compute_stats=True)\n",
    "print('Unmodulated and RT-modulated (centered RT)')\n",
    "print(con_cons_rt_mod)\n",
    "#print(p_cons_rt_mod)\n",
    "\n",
    "print(mn_rt)\n",
    "\n",
    "fit_cons_dur_only = con_cons_rt[0] + con_cons_rt[1]*unmod_reg\n",
    "\n",
    "#plt.plot(bold, label = 'data')\n",
    "#plt.plot(mod_fit_dur_rt, label = 'model fit var epoch')\n",
    "#plt.plot(mod_fit_cons_rt, label='model fit cons dur + orthog var epoch')\n",
    "#plt.plot(mod_fit_cons_rt_mod, label='model fit cons dur + rt mod')\n",
    "#plt.plot(fit_cons_dur_only, label='only cons dur from cons dur + rt mod')\n",
    "#plt.legend(loc = 'upper left', prop={'size': 6})\n",
    "#plt.show()\n",
    "\n",
    "#plt.plot(con_dur_rt[0] + mn_rt_dur*con_dur_rt[1], \n",
    "#        label='intercept + mn rt x rt_dur (rt dur model)')\n",
    "#plt.plot(fit_cons_dur_only, label = 'only cons dur from cons dur + rt mod')\n",
    "#plt.legend(loc = 'upper right', prop={'size': 6})\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_est_beta_rt_shift(gamma_loc, gamma_alpha, gamma_beta, cons_dur_val, nsim):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    sim_out = {\"beta_rt\", \"beta_cons_orth\", \"beta_rt_orth\",\n",
    "               \"beta_cons_mod\", \"beta_rt_mod\", \"beta_cons_dur_mn_rt\", \"beta_rt_dur_mn_rt\",\n",
    "               \"p_rt\", \"p_cons_orth\", \"p_rt_orth\",\n",
    "               \"p_cons_mod\", \"p_rt_mod\", \"p_cons_dur_mn_rt\", \"p_rt_dur_mn_rt\", \"mn_rt_all\"}\n",
    "    output_dict = {key: [] for key in sim_out} \n",
    "    for sim in range(0, nsim):\n",
    "        frame_times = np.arange(500)\n",
    "        scan_length = len(frame_times)\n",
    "        onsets = np.arange(10, 480, 10)\n",
    "        duration_rt = gamma.rvs(a = gamma_alpha, loc = gamma_loc, scale = gamma_beta, size = onsets.shape)\n",
    "        amplitude_1 = np.ones(onsets.shape)\n",
    "        mn_rt = np.mean(duration_rt)\n",
    "        output_dict[\"mn_rt_all\"].append(round(mn_rt, 5))\n",
    "        duration_cons = np.ones(onsets.shape)*cons_dur_val\n",
    "        duration_impulse = np.ones(onsets.shape)*.1 \n",
    "        amplitude_rt_centered = duration_rt - mn_rt\n",
    "        mn_rt_dur = np.ones(onsets.shape)*mn_rt\n",
    "        rt_dur_reg_info = make_3column_onsets(onsets, duration_rt, amplitude_1)\n",
    "        unmod_mnrt_dur_reg_info = make_3column_onsets(onsets, mn_rt_dur, amplitude_1)\n",
    "        imp_reg_info = make_3column_onsets(onsets, duration_impulse, amplitude_1)\n",
    "        unmod_reg_info = make_3column_onsets(onsets, duration_cons, amplitude_1)\n",
    "        mod_rt_centered_reg_info = make_3column_onsets(onsets, duration_cons, amplitude_rt_centered)\n",
    "        \n",
    "        rt_dur, _ = hemodynamic_models.compute_regressor(\n",
    "                      rt_dur_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "        imp_dur, _ = hemodynamic_models.compute_regressor(\n",
    "                      imp_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "        unmod_reg, _ = hemodynamic_models.compute_regressor(\n",
    "                      unmod_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "        unmod_mnrt_dur_reg, _ = hemodynamic_models.compute_regressor(\n",
    "                      unmod_mnrt_dur_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "        mod_rt, _ = hemodynamic_models.compute_regressor(\n",
    "                      mod_rt_centered_reg_info, 'spm', frame_times, \n",
    "                      oversampling=16)\n",
    "        # orthogonalize by first fitting unmod to rt_dur\n",
    "        #x_unmod_only = sm.add_constant(unmod_reg)\n",
    "        #contrasts = np.array([[0, 1]])\n",
    "        #_, _, _, predy, _ = runreg(rt_dur, x_unmod_only, contrasts, hp_filter=False, \n",
    "        #                           compute_stats=False)\n",
    "        contrasts = np.array([[1]])\n",
    "        _, _, _, predy, _ = runreg(rt_dur, unmod_reg, contrasts, hp_filter=False, \n",
    "                           compute_stats=False)\n",
    "        rt_dur_orth = rt_dur - predy\n",
    "        # Same as above, but for mn_rt_dur regressor\n",
    "        _, _, _, predy, _ = runreg(rt_dur, unmod_mnrt_dur_reg, contrasts, hp_filter=False, \n",
    "                           compute_stats=False)\n",
    "        rt_dur_orth_mnrt_dur = rt_dur - predy\n",
    "        # Orthogonalize in neural space (sort of)\n",
    "        #rt_dur_orth_reg_info = make_3column_onsets(np.array(onsets)+cons_dur_val, \n",
    "        #                                   np.array(duration_rt)-cons_dur_val, amplitude_1)\n",
    "        #\n",
    "        #rt_dur_orth_reg_info = make_3column_onsets(np.array(onsets), \n",
    "        #                                   duration_rt, amplitude_1)\n",
    "        #rt_dur_orth, _ = hemodynamic_models.compute_regressor(\n",
    "        #              rt_dur_orth_reg_info, 'spm', frame_times, \n",
    "        #              oversampling=16)  \n",
    "        bold = 100 + rt_dur*5 + np.random.normal(0, 5, (scan_length, 1))\n",
    "        contrasts = np.array([[1, 0], [0, 1]])\n",
    "        x_rt_dur = sm.add_constant(rt_dur)\n",
    "        con_dur_rt, t_dur_rt, p_dur_rt, mod_fit_dur_rt, _ = runreg(bold, x_rt_dur, \n",
    "                                contrasts, hp_filter=False, compute_stats=True)\n",
    "        output_dict[\"beta_rt\"].append(round(con_dur_rt[1], 3))\n",
    "        output_dict[\"p_rt\"].append(p_dur_rt[1])\n",
    "\n",
    "        contrasts = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "        x_cons_rt = np.concatenate((np.ones(unmod_reg.shape), unmod_reg, rt_dur_orth), axis=1)\n",
    "        con_cons_rt, t_cons_rt, p_cons_rt, mod_fit_cons_rt, _ = runreg(bold, x_cons_rt, contrasts,\n",
    "                  hp_filter=False, compute_stats=True)\n",
    "        output_dict[\"beta_cons_orth\"].append(round(con_cons_rt[1], 3))\n",
    "        output_dict[\"beta_rt_orth\"].append(round(con_cons_rt[2], 3))\n",
    "        output_dict[\"p_cons_orth\"].append(p_cons_rt[1])\n",
    "        output_dict[\"p_rt_orth\"].append(p_cons_rt[2])\n",
    "\n",
    "        x_cons_rt_mod = np.concatenate((np.ones(unmod_reg.shape), unmod_reg, mod_rt), axis=1)\n",
    "        con_cons_rt_mod, t_cons_rt_mod, p_cons_rt_mod, mod_fit_cons_rt_mod, _ = runreg(bold, \n",
    "                  x_cons_rt_mod, contrasts, hp_filter=False, compute_stats=True)\n",
    "        output_dict[\"beta_cons_mod\"].append(round(con_cons_rt_mod[1], 3))\n",
    "        output_dict[\"beta_rt_mod\"].append(round(con_cons_rt_mod[2], 3))\n",
    "        output_dict[\"p_cons_mod\"].append(p_cons_rt_mod[1])\n",
    "        output_dict[\"p_rt_mod\"].append(p_cons_rt_mod[2])\n",
    "\n",
    "        x_consmnrt_rt_mod = np.concatenate((np.ones(unmod_reg.shape),\n",
    "                                           unmod_mnrt_dur_reg,\n",
    "                                           rt_dur_orth_mnrt_dur), axis=1)\n",
    "        con_consmnrt_rt_mod, t_consmnrt_rt_mod, p_consmnrt_rt_mod, mod_fit_consmnrt_rt_mod, _ = runreg(bold, \n",
    "                  x_consmnrt_rt_mod, contrasts, hp_filter=False, compute_stats=True)\n",
    "        output_dict[\"beta_cons_dur_mn_rt\"].append(round(con_consmnrt_rt_mod[1], 3))\n",
    "        output_dict[\"beta_rt_dur_mn_rt\"].append(round(con_consmnrt_rt_mod[2], 3))\n",
    "        output_dict[\"p_cons_dur_mn_rt\"].append(p_consmnrt_rt_mod[1])\n",
    "        output_dict[\"p_rt_dur_mn_rt\"].append(p_consmnrt_rt_mod[2])\n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma fit to stroop\n",
    "#(alpha=4.346889671597502, loc=0.2929374058963791, beta(scale)=0.10467336895045937)\n",
    "gamma_loc = 0.5\n",
    "gamma_alpha = 1.7\n",
    "gamma_beta = .49\n",
    "#gamma_loc = 0.5\n",
    "#gamma_alpha = 4.35\n",
    "#gamma_beta = .10\n",
    "print(np.mean(gamma.rvs(a = gamma_alpha, loc = gamma_loc, scale = gamma_beta, size = 3000)))\n",
    "cons_dur_val = 1\n",
    "nsim = 1000\n",
    "out = sim_est_beta_rt_shift(gamma_loc, gamma_alpha, gamma_beta, cons_dur_val, nsim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.array(out[\"p_rt\"])<=0.05))\n",
    "print(np.mean(np.array(out[\"p_cons_orth\"])<=0.05))\n",
    "print(np.mean(np.array(out[\"p_cons_mod\"])<=0.05))\n",
    "print(np.mean(np.array(out[\"p_cons_dur_mn_rt\"])<=0.05))\n",
    "print('rt regressors')\n",
    "print(np.mean(np.array(out[\"p_rt_orth\"])<=0.05))\n",
    "print(np.mean(np.array(out[\"p_rt_mod\"])<=0.05))\n",
    "print(np.mean(np.array(out[\"p_rt_dur_mn_rt\"])<=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist([out[\"beta_rt\"], out[\"beta_cons_orth\"], out[\"beta_cons_mod\"]],\n",
    "         label=['RT duration', 'Cons orth model', 'Cons mod model'])\n",
    "plt.title('Parameter estimates')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.hist([out[\"beta_rt\"], out[\"beta_rt_orth\"], out[\"beta_rt_mod\"]],\n",
    "         label=['RT duration', 'RT orth model', 'RT mod model'])\n",
    "plt.title('Parameter estimates')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(out[\"mn_rt_all\"])\n",
    "plt.title('RT distribution (mean from each simulation)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"mean RT over simulations\")\n",
    "print(np.mean(out[\"mn_rt_all\"]))\n",
    "#print(\"Activation times mean RT divided by duration of the constant reg\")\n",
    "#print(np.mean(out[\"mn_rt_all\"])*5)\n",
    "print(\"True activation\")\n",
    "print(np.mean(out[\"beta_rt\"]))\n",
    "print(\"Mean activation for cons orth model\")\n",
    "print(np.mean(out[\"beta_cons_orth\"]))\n",
    "print(\"Mean activation for cons(meanRT) orth model\")\n",
    "print(np.mean(out[\"beta_cons_dur_mn_rt\"]))\n",
    "print(\"Mean activation for cons orth model divided by mean RT\")\n",
    "print(np.mean(out[\"beta_cons_orth\"])/np.mean(out[\"mn_rt_all\"]))\n",
    "print(\"Mean activation for cons modulation model\")\n",
    "print(np.mean(out[\"beta_cons_mod\"]))\n",
    "print(\"Mean activation for rt in orth model\")\n",
    "print(np.mean(out[\"beta_rt_orth\"]))\n",
    "print(\"Mean activation for rt in orth model (dur=mean(RT)\")\n",
    "print(np.mean(out[\"beta_rt_dur_mn_rt\"]))\n",
    "print(\"Mean activation for rt in modulation model\")\n",
    "print(np.mean(out[\"beta_rt_mod\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above I'm currently guessing the mean activation from the orthogonalization model is the true activation multiplied by the mean RT.  This will likely vary according to how long the duration of the constant duration regressor is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample RT's from the RT distribution in hierarchical way. \n",
    "#  Look at within-subject R^1 and parameter estimates to see if\n",
    "# they correlate with subject mean RT.  I'm using the Grinband\n",
    "# settings since that's where I'm also seeing single subject power differences\n",
    "# Goal is to see if misfit is present and also whether the unmodulated PEs are biased\n",
    "\n",
    "# Hypothesis, the orthogonalized model will be perfectly fine.  I already know the RT\n",
    "# modulated models will fail in some way.\n",
    "\n",
    "n_trials = 30\n",
    "scan_length = 225\n",
    "repetition_time = 1\n",
    "mu_grinband_shift = 642.35\n",
    "inv_lambda_grinband_shift = 689.75\n",
    "sigma_grinband_shift = 104.80\n",
    "mu_expnorm = mu_grinband_shift\n",
    "lam_expnorm = 1 / inv_lambda_grinband_shift\n",
    "sigma_expnorm = sigma_grinband_shift\n",
    "max_rt = 8000\n",
    "min_rt = 50\n",
    "event_duration = 1\n",
    "beta_scales_yes = 1.5\n",
    "beta_scales_no = 20\n",
    "nsim = 100\n",
    "center_rt=True\n",
    "hp_filter = True\n",
    "\n",
    "ISI_min = 3\n",
    "ISI_max = 6\n",
    "win_sub_noise_sd = 1\n",
    "btwn_sub_noise_sd = 1\n",
    "nsub = 30\n",
    "\n",
    "lev1_out = lev1_many_subs(n_trials, scan_length, repetition_time, mu_expnorm,\n",
    "              lam_expnorm, sigma_expnorm, max_rt, \n",
    "              min_rt, event_duration, ISI_min, ISI_max, win_sub_noise_sd, btwn_sub_noise_sd, nsub,\n",
    "              center_rt, beta_scales_yes, beta_scales_no, hp_filter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(lev1_out['rt_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lev1_out['r2']['dv_scales_yes']['Stimulus Duration'],\n",
    "         lev1_out['unmod_beta_est']['dv_scales_yes']['Stimulus Duration'], 'o')      \n",
    "plt.xlabel('R-squared lev1 mod')\n",
    "plt.ylabel('Beta const dur reg from RTmod model')\n",
    "plt.title('Scales = Yes')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lev1_out['rt_mean'],\n",
    "         lev1_out['unmod_beta_est']['dv_scales_yes']['Stimulus Duration'], 'o')      \n",
    "plt.xlabel('Mean RT')\n",
    "plt.ylabel('Beta const dur reg from RTmod model')\n",
    "plt.title('Scales = Yes')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lev1_out['r2']['dv_scales_yes']['Stimulus Duration'],\n",
    "         lev1_out['rt_mean'], 'o')      \n",
    "plt.xlabel('R-squared lev1 mod')\n",
    "plt.ylabel('mean RT')\n",
    "plt.title('Scales = Yes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lev1_out['r2']['dv_scales_yes']['Fixed event Duration and RT Duration orth'],\n",
    "         lev1_out['unmod_beta_est']['dv_scales_yes']['Fixed event Duration and RT Duration orth'], 'o')      \n",
    "plt.xlabel('R-squared lev1 mod')\n",
    "plt.ylabel('Beta const dur reg from RT orth model')\n",
    "plt.title('Scales = Yes')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lev1_out['rt_mean'],\n",
    "         lev1_out['unmod_beta_est']['dv_scales_yes']['Fixed event Duration and RT Duration orth'], 'o')      \n",
    "plt.xlabel('Mean RT')\n",
    "plt.ylabel('Beta const dur reg from RT orth model')\n",
    "plt.title('Scales = Yes')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lev1_out['r2']['dv_scales_yes']['Fixed event Duration and RT Duration orth'],\n",
    "         lev1_out['rt_mean'], 'o')      \n",
    "plt.xlabel('R-squared lev1 mod')\n",
    "plt.ylabel('mean RT')\n",
    "plt.title('Scales = Yes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't make sense to look at R-squared.  At least I don't think so.  It goes up with beta no matter what and this might simply be a power thing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to estimate total within-subject variance for a beta (not just the residual variance)\n",
    "\n",
    "out_est_win_sub_var = est_win_sub_var(n_trials, scan_length, repetition_time, mu_expnorm,\n",
    "              lam_expnorm, sigma_expnorm, max_rt, \n",
    "              min_rt, event_duration, ISI_min, ISI_max, win_sub_noise_sd, center_rt,\n",
    "              beta_scales_yes, beta_scales_no, hp_filter)\n",
    "\n",
    "print(out_est_win_sub_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just use the regular function for calculating power\n",
    "\n",
    "n_trials = 30\n",
    "scan_length = 225\n",
    "repetition_time = 1\n",
    "mu_grinband_shift = 642.35\n",
    "inv_lambda_grinband_shift = 689.75\n",
    "sigma_grinband_shift = 104.80\n",
    "#mu_expnorm = 530\n",
    "#lam_expnorm = 1 / 160\n",
    "#sigma_expnorm = 77\n",
    "mu_expnorm = mu_grinband_shift\n",
    "lam_expnorm = 1 / inv_lambda_grinband_shift\n",
    "sigma_expnorm = sigma_grinband_shift\n",
    "max_rt = 8000\n",
    "min_rt = 50\n",
    "#max_rt = 3000\n",
    "#min_rt = 0\n",
    "event_duration = .5\n",
    "#event_duration = .5\n",
    "#beta_scales_yes = 1.5\n",
    "beta_scales_yes = 5\n",
    "beta_scales_no = 70\n",
    "center_rt=True\n",
    "hp_filter = True\n",
    "\n",
    "ISI_min = 3\n",
    "ISI_max = 6\n",
    "#ISI_min = 2\n",
    "#ISI_max = 2\n",
    "\n",
    "\n",
    "nsim = 500\n",
    "nsub = 10\n",
    "win_sub_noise_sd = 2.5 # 2.5 corresponds to a within-subject beta sd of 1.5\n",
    "btwn_sub_noise_sd = 5  # I think i'll go between 1-3?  With within sd = 2.5\n",
    "\n",
    "des_sd = np.sqrt(.64)\n",
    "print('ratio of total sd to within-sub sd')\n",
    "print(np.sqrt((win_sub_noise_sd*des_sd)**2 + btwn_sub_noise_sd**2)/(win_sub_noise_sd*des_sd))\n",
    "print('Cohens D estimate')\n",
    "mfx_sd = np.sqrt((win_sub_noise_sd*des_sd)**2 + btwn_sub_noise_sd**2)\n",
    "print(beta_scales_yes/mfx_sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unmod_cor_with_rt_corplot, rtmod_cor_with_rt_corplot, unmod_p_1sampt_pow, rtmod_p_1sampt_pow = \\\n",
    "              many_sim_fit_group(n_trials, scan_length, repetition_time, \n",
    "              mu_expnorm, lam_expnorm, sigma_expnorm, max_rt, \n",
    "              min_rt, event_duration, ISI_min, ISI_max, win_sub_noise_sd, btwn_sub_noise_sd, nsub, nsim, \n",
    "              center_rt, beta_scales_yes, beta_scales_no, hp_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_unmod_1sampt = {key: {key2: {} for key2 in unmod_p_1sampt_pow['dv_scales_yes']} \\\n",
    "        for key in unmod_p_1sampt_pow}\n",
    "power_rtmod_1sampt = {key: {key2: {} for key2 in rtmod_p_1sampt_pow['dv_scales_yes']} \\\n",
    "        for key in rtmod_p_1sampt_pow}\n",
    "for i in unmod_p_1sampt_pow.keys():\n",
    "        for j in unmod_p_1sampt_pow[i].keys():\n",
    "            pvals_loop = np.array(unmod_p_1sampt_pow[i][j])\n",
    "            power_unmod_1sampt[i][j] = np.mean(pvals_loop<0.05)\n",
    "            pvals_loop = np.array(rtmod_p_1sampt_pow[i][j])\n",
    "            power_rtmod_1sampt[i][j] = np.mean(pvals_loop<0.05)\n",
    "\n",
    "\n",
    "print(power_unmod_1sampt)\n",
    "print(power_rtmod_1sampt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cor_violin(unmod_cor_with_rt_corplot, rtmod_cor_with_rt_corplot, \n",
    "                    mu_expnorm, lam_expnorm, sigma_expnorm, ISI_min, ISI_max, \n",
    "                    win_sub_noise_sd, btwn_sub_noise_sd, nsub, nsim, \n",
    "                    beta_scales_yes, beta_scales_no, hp_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/jeanettemumford/Dropbox/Research/Projects/RT_sims/Code')\n",
    "from functions import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.stats import exponnorm, gamma\n",
    "\n",
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmodulated_scales_yes = pd.DataFrame(unmod_cor_with_rt_corplot['dv_scales_yes'])\n",
    "unmodulated_scales_yes['True Signal'] = 'Scales with RT'\n",
    "unmodulated_scales_no = pd.DataFrame(unmod_cor_with_rt_corplot['dv_scales_no'])\n",
    "unmodulated_scales_no['True Signal'] = 'Does not scale with RT'\n",
    "dat_unmodulated = pd.concat([unmodulated_scales_yes, unmodulated_scales_no])\n",
    "unmod_long = pd.melt(dat_unmodulated, id_vars = 'True Signal')\n",
    "unmod_long['Lower Level Estimate'] = 'Stimulus vs baseline'\n",
    "\n",
    "rtmodulated_scales_yes = pd.DataFrame(rtmod_cor_with_rt_corplot['dv_scales_yes'])\n",
    "rtmodulated_scales_yes['True Signal'] = 'Scales with RT'\n",
    "rtmodulated_scales_no = pd.DataFrame(rtmod_cor_with_rt_corplot['dv_scales_no'])\n",
    "rtmodulated_scales_no['True Signal'] = 'Does not scale with RT'\n",
    "dat_rtmodulated = pd.concat([rtmodulated_scales_yes, rtmodulated_scales_no])\n",
    "rtmod_long = pd.melt(dat_rtmodulated, id_vars = 'True Signal')\n",
    "rtmod_long['Lower Level Estimate'] = 'RT modulation'\n",
    "\n",
    "dat_long = pd.concat([rtmod_long, unmod_long])\n",
    "dat_long['Lower Level Estimate'] = \\\n",
    "                          dat_long['Lower Level Estimate'].astype('category')\n",
    "dat_long['Lower Level Estimate'] = \\\n",
    "             dat_long['Lower Level Estimate'].cat.reorder_categories(\\\n",
    "                 ['Stimulus vs baseline',\n",
    "                 'RT modulation']) \n",
    "\n",
    "#makeNA = ((dat_long['Lower Level Estimate'] == \n",
    "#           'Stimulus vs baseline') & \\\n",
    "#         (dat_long['variable'] == 'RT Duration only')) | \\\n",
    "#         ((dat_long['Lower Level Estimate'] == \n",
    "#           'RT modulation') & \\\n",
    "#         (dat_long['variable'] == 'No RT effect'))\n",
    "#dat_long.loc[makeNA, 'value'] = np.nan\n",
    "\n",
    "cor_t_cutoff = abs(t.ppf(.025, nsub))\n",
    "cor_cutoff = cor_t_cutoff/(nsub - 2 +cor_t_cutoff**2)**.5\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=2)\n",
    "g = sns.catplot(data = dat_long, x='variable', y='value',\n",
    "                hue='True Signal', row='Lower Level Estimate', kind='violin',\n",
    "                palette='bright',  aspect = 5, height =4)\n",
    "g.set_ylabels('Correlation',size=30)\n",
    "g.set_xlabels('',size=30, clear_inner=False)\n",
    "titles = [r'Task vs baseline: Cor($\\hat\\beta_{trial}$, $RT_{WS}$)', r'Cor($\\hat\\beta_{RT_{BT}}$ , $RT_{WS}$)']\n",
    "for count, ax in enumerate(g.axes.flatten()):\n",
    "    ax.tick_params(labelbottom=True)\n",
    "    ax.axhline(0, color='black')\n",
    "    ax.axhline(cor_cutoff, linestyle='dashed', color='gray')\n",
    "    ax.axhline(-1*cor_cutoff, linestyle='dashed', color='gray')\n",
    "    ax.set_title(titles[count])\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "#fig_root = Path('/Users/jeanettemumford/Dropbox/Research/Talks/OHBM2021/Poster/Figures/')\n",
    "#plt.savefig(fig_root / \"rt_cor_plot.eps\",\n",
    "#            format='eps', transparent=True, pad_inches=.5, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "power_1sampt = {key: {key2: {} for key2 in p_val_1sampt_pow['dv_scales_yes']} \\\n",
    "        for key in p_val_1sampt_pow}\n",
    "power_adj_1sampt = {key: {key2: {} for key2 in p_val_1sampt_pow['dv_scales_yes']} \\\n",
    "        for key in p_val_1sampt_pow}\n",
    "for i in p_val_1sampt_pow.keys():\n",
    "        for j in p_val_1sampt_pow[i].keys():\n",
    "            pvals_loop = np.array(p_val_1sampt_pow[i][j])\n",
    "            power_1sampt[i][j] = np.mean(pvals_loop<0.05)\n",
    "            pvals_loop2 = np.array(p_val_adj_1_sampt_pow[i][j])\n",
    "            power_adj_1sampt[i][j] = np.mean(pvals_loop2<0.05)\n",
    "\n",
    "\n",
    "print(power_1sampt)\n",
    "print(power_adj_1sampt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "941e4752b19feded12202230476416525a981815ea3500c2dcd589733ac9bd5f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8.5': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
